{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7orIedGckTt8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmmr2_EpuuRL"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m48BNoQUk9x-"
      },
      "outputs": [],
      "source": [
        "# Reading the Training Data\n",
        "df = pd.read_csv(\"/kaggle/input/train_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Displaying the first 10 records\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Check dataset info - field types, non-null values, dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3a. Pre-processing (Cleaning): Address missing (NULL) values - drop or imputation\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3b. Pre-processing (Cleaning): Remove Duplicate Rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3c. Pre-processing (Cleaning): Drop irrelevant columns (that you don't want to give as input to the model)\n",
        "df = df.drop(columns=[\"id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3d. Pre-processing (Encoding): Convert categorical values to numeric\n",
        "# Use df['col_name'].value_counts() to find out all the categories available per column\n",
        "\n",
        "df['col_name'].value_counts()\n",
        "\n",
        "df = pd.get_dummies(df, columns = ['content_rating']) # Pandas function to convert 'objects' (categorical) to one-hot (new col per category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4a. Data understanding - Find out stats regarding your data (df.describe(), df.mean(), df.median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4b. Data understanding - Make use of plots to build more understanding of the data\n",
        "# Hint: Can use df.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4b. (Optional) Create More plots to understand the relationship b/w different variables\n",
        "\n",
        "# Example: Top 20 actors of movies based on the imdb rating of the movies\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Create a new dataframe with top 20 values\n",
        "new_df = df.sort_values(by ='imdb_score' , ascending=False)\n",
        "new_df = new_df.head(20)\n",
        "\n",
        "# plotting\n",
        "ax=sns.pointplot(x=new_df['actor_1_name'], y=new_df['imdb_score'], hue=new_df['movie_title'])\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4c. Find out which input features are the most important\n",
        "# Hint: Start out with df.corr(). Can visualise with seaborn library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Any other relevant pre-processing (upto your exploration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Divide dataframe into input and output\n",
        "# X = df.drop(columns=['output_class']) -> Drop the column to be predicted\n",
        "# y = df['output_class'] -> Choose Output column to be predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Perform Feature Selection - Experiment with the best one!\n",
        "feat_selector = SelectKBest(mutual_info_classif, k=3)\n",
        "X = feat_selector.fit_transform(X, y)\n",
        "chosen_features = feat_selector.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usually, we do a train-test split, but, in the hackathon, we'll already provide you with the separate datasets for each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Data Normalisation: Bring into the range 0 to 1, or -1 to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNFBi9jyk90_"
      },
      "outputs": [],
      "source": [
        "# 4. Choose Model(s), fit\n",
        "### Experiment with different models.\n",
        "### https://scikit-learn.org/stable/supervised_learning.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HzvdnG0mWEZ"
      },
      "outputs": [],
      "source": [
        "# 5. Evaluate with relevant metric for your problem. Eg: accuracy_score(), r2_score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. After model choice is made, fine-tune with GridSearchCV, or RandomizedSearchCV()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zb-W-KzvyzX"
      },
      "source": [
        "### Testing and Creating Output CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X833FyDYv0IY"
      },
      "outputs": [],
      "source": [
        "# Creating output file for submission - Template Code\n",
        "\n",
        "test_pd = pd.read_csv('/kaggle/input/test-imdb/test_data_with_inputs.csv')\n",
        "\n",
        "# saving in a new variable to modify\n",
        "test = test_pd.copy(deep=True)\n",
        "\n",
        "# Prepare data to be given as an input to your trained model\n",
        "# 1. Repeat the pre-processing done above. Eg: Conversion to categorical, filling in mean values\n",
        "test['bmi'].fillna(test['bmi'].mean(), inplace=True)\n",
        "test = pd.get_dummies(test)\n",
        "\n",
        "# 2. Use the same features obtained in feature selection\n",
        "chosen_features = feat_selector.get_feature_names_out() # from above -> getting names of chosen features\n",
        "test = test[chosen_features]\n",
        "\n",
        "# 3. Normalise/Scale the features as done above\n",
        "\n",
        "\n",
        "# 4. Predict and obtain results from the model\n",
        "y_pred = model.predict(test)\n",
        "\n",
        "# 5. Save results to CSV\n",
        "submission = pd.DataFrame({'ID': test_pd.index, 'stroke' : y_pred})\n",
        "submission.to_csv('output_submission_eval.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRKZLwnaoFQf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
